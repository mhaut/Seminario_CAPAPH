{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminario de Invierno. CAPAP-H\n",
    "# Cáceres. 29-31 Enero 2025\n",
    "\n",
    "#### Juan Mario Haut Hurtado. Correo: juanmariohaut@unex.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de datos en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para manejar los datos en PyTorch disponemos de dos clases principales:\n",
    "1. **Dataset**: Clase abstracta que define la interfaz para todos los datasets en PyTorch.\n",
    "2. **Dataloader** : Clase que nos permite cargar los datos de un dataset en lotes para su procesamiento. Además, nos permite mezclar aleatoriamente los datos y cargarlos en paralelo utilizando múltiples subprocesos. El dataloader es especialmente útil cuando trabajamos con grandes conjuntos de datos que no caben en la memoria RAM de nuestro ordenador. En lugar de cargar todo el conjunto de datos en la memoria RAM, podemos cargar los datos en lotes y procesarlos de forma incremental.\n",
    "\n",
    "En este notebook nos centraremos en la clase **Dataloader**. Esta clase nos permite realizar muchas operaciones **imprescindibles** para el entrenamiento de una red. Veamos un ejemplo partiendo del ejemplo de **Dataset**. API: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Definimos una clase para nuestro dataset\n",
    "class MiDataset(Dataset):\n",
    "    def __init__(self, datos):\n",
    "        self.datos = datos\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datos)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.datos[idx]\n",
    "\n",
    "# Creamos un dataset de ejemplo\n",
    "datos = [1, 2, 3, 4, 5]\n",
    "dataset = MiDataset(datos)\n",
    "\n",
    "# Creamos un dataloader para nuestro dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Iteramos sobre el dataloader\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"/tmp\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"/tmp\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Creamos un dataloader para nuestro dataset\n",
    "dataloader = DataLoader(training_data, batch_size=9, shuffle=True)\n",
    "\n",
    "# Iteramos sobre el dataloader\n",
    "for idbatch, (X,y) in enumerate(dataloader):\n",
    "    print(X.shape, y)\n",
    "    if idbatch == 5: \n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        cols, rows = 3, 3\n",
    "        for i in range(cols * rows):\n",
    "            img, label = X[i], y[i]\n",
    "            figure.add_subplot(rows, cols, i+1)\n",
    "            plt.title(labels_map[int(label)])\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar FashionMNIST por MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation es una técnica utilizada en el aprendizaje automático para aumentar la cantidad de datos de entrenamiento mediante la creación de nuevas muestras a partir de las muestras existentes. La idea detrás de la data augmentation es que, al aumentar la cantidad de datos de entrenamiento, podemos mejorar la capacidad de generalización del modelo y reducir el sobreajuste.\n",
    "\n",
    "La data augmentation se aplica típicamente a conjuntos de datos de imágenes y consiste en aplicar transformaciones aleatorias a las imágenes existentes, como rotaciones, traslaciones, zooms, cambios de brillo y contraste, entre otros. Estas transformaciones crean nuevas imágenes que son similares a las originales, pero que presentan variaciones que pueden ayudar al modelo a generalizar mejor.\n",
    "\n",
    "La data augmentation también se puede aplicar a otros tipos de datos, como audio y texto, mediante técnicas específicas para cada tipo de dato. En general, la data augmentation es una técnica muy útil para mejorar el rendimiento de los modelos de aprendizaje automático, especialmente cuando se dispone de conjuntos de datos pequeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Definimos las transformaciones de data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Definimos las transformaciones de data augmentation\n",
    "transform_train2 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Cargamos el conjunto de datos CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='/tmp', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Cargamos el conjunto de datos CIFAR-10\n",
    "trainset2 = torchvision.datasets.CIFAR10(\n",
    "    root='/tmp', train=True, download=True, transform=transform_train2)\n",
    "\n",
    "# Creamos un dataloader para cargar los datos en lotes\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Iteramos sobre el dataloader y mostramos algunas imágenes generadas por data augmentation\n",
    "for images, labels in trainloader:\n",
    "    # Mostramos las primeras 9 imágenes del lote\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))\n",
    "        plt.title(labels_map[labels[i].item()])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# Creamos un dataloader para cargar los datos en lotes\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset2, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Iteramos sobre el dataloader y mostramos algunas imágenes generadas por data augmentation\n",
    "for images, labels in trainloader:\n",
    "    # Mostramos las primeras 9 imágenes del lote\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))\n",
    "        plt.title(labels_map[labels[i].item()])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este ejemplo, definimos las transformaciones de data augmentation utilizando la clase `Compose` de `torchvision.transforms`. En este caso, aplicamos una transformación de recorte aleatorio (`RandomCrop`), una transformación de volteo horizontal aleatorio (`RandomHorizontalFlip`), una transformación de conversión a tensor (`ToTensor`) y una transformación de normalización (`Normalize`).\n",
    "\n",
    "Luego, cargamos el conjunto de datos CIFAR-10 utilizando la clase `CIFAR10` de `torchvision.datasets` y especificamos las transformaciones de data augmentation que queremos aplicar.\n",
    "\n",
    "Finalmente, creamos un dataloader utilizando la clase `DataLoader` de PyTorch y especificamos el tamaño de lote (`batch_size`), el mezclado aleatorio (`shuffle`) y el número de subprocesos (`num_workers`) que queremos utilizar.\n",
    "\n",
    "Luego, iteramos sobre el dataloader y mostramos algunas imágenes generadas por data augmentation utilizando la librería `matplotlib`. En este caso, mostramos las primeras 9 imágenes del lote.\n",
    "\n",
    "Espero que esto te sea útil. Si tienes alguna pregunta, no dudes en preguntar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arqesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
